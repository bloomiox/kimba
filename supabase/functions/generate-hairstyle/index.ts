// Follow the official Supabase guide to deploy this function:
// https://supabase.com/docs/guides/functions

import { GoogleGenAI, Modality } from 'npm:@google/genai';

// FIX: Declare Deno to satisfy TypeScript compiler in non-Deno environments.
declare const Deno: any;

// IMPORTANT: Set your Gemini API key in your Supabase project's secrets.
// Go to Project Settings > Edge Functions > Add new secret
// Name: GEMINI_API_KEY, Value: your_api_key
const API_KEY = Deno.env.get('GEMINI_API_KEY');
if (!API_KEY) {
  throw new Error('GEMINI_API_KEY environment variable not set');
}
const ai = new GoogleGenAI({ apiKey: API_KEY });

// Helper to strip data URL prefix if present
const stripDataUrlPrefix = (base64String: string): string => {
  return base64String.split(',')[1] || base64String;
};

Deno.serve(async (req: Request) => {
  // Handle CORS preflight request
  if (req.method === 'OPTIONS') {
    return new Response('ok', { 
        headers: {
            'Access-Control-Allow-Origin': '*',
            'Access-Control-Allow-Headers': 'authorization, x-client-info, apikey, content-type',
        } 
    });
  }

  try {
    const { base64Image, mimeType, prompt, referenceImage } = await req.json();

    if (!base64Image || !mimeType || !prompt) {
      return new Response(JSON.stringify({ error: 'Missing required parameters.' }), {
        status: 400,
        headers: { 'Content-Type': 'application/json', 'Access-Control-Allow-Origin': '*' },
      });
    }

    const clientImageData = stripDataUrlPrefix(base64Image);
    const parts: any[] = [{ inlineData: { data: clientImageData, mimeType } }];
    let textPrompt = '';

    if (referenceImage) {
        const referenceImageData = stripDataUrlPrefix(referenceImage.base64);
        parts.push({ inlineData: { data: referenceImageData, mimeType: referenceImage.mimeType } });
        textPrompt = `From the second image, extract the hairstyle. Apply this hairstyle to the person in the first image. Additional instructions: ${prompt}. Maintain the client's facial features and the background from the first image. The final image should only contain the client with the new hairstyle.`;
    } else {
        textPrompt = `Apply this hairstyle to the person: ${prompt}. Maintain the person's facial features and the background.`;
    }
    parts.push({ text: textPrompt });

    const response = await ai.models.generateContent({
        model: 'gemini-2.5-flash-image-preview',
        contents: { parts },
        config: {
            responseModalities: [Modality.IMAGE, Modality.TEXT],
        },
    });

    const candidate = response.candidates?.[0];

    if (candidate?.content?.parts) {
      const imagePart = candidate.content.parts.find(p => p.inlineData);
      if (imagePart?.inlineData) {
        return new Response(JSON.stringify({ base64Image: imagePart.inlineData.data }), {
          headers: { 'Content-Type': 'application/json', 'Access-Control-Allow-Origin': '*' },
        });
      }
    }

    if (candidate?.finishReason && candidate.finishReason !== 'STOP') {
        const reason = `Image generation was blocked. Reason: ${candidate.finishReason}.`;
        return new Response(JSON.stringify({ error: reason }), {
          status: 500,
          headers: { 'Content-Type': 'application/json', 'Access-Control-Allow-Origin': '*' },
        });
    }

    throw new Error('No image was generated by the model.');

  } catch (error) {
    console.error(error);
    return new Response(JSON.stringify({ error: error.message }), {
      status: 500,
      headers: { 'Content-Type': 'application/json', 'Access-Control-Allow-Origin': '*' },
    });
  }
});
